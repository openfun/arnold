# Concepts

In this section, we will define every word and concept that we will be dealing
with in the code and the documentation of the project.

## Customers and environments

What we call a customer is more or less an hosted instance of Open edX.

A customer instance can be installed in several environments. We currently
defined five different ones:

* **development**: deploy our projects to MiniShift on developer's laptops,
* **feature**: one environment for each feature branch, the feature being
  described by its title (**e.g** `feat/99-change-background-color`),
* **staging**: aggregating all features before a release,
* **preprod**: validating a release before going live,
* **production**: customer facing operations.

In order to deploy our applications, we need to generate configuration files
customized for each project, being defined by a customer site AND an
environment.

## Project and application names

A project name is used for `OpenShift` projects and it is generated using the
following pattern:

    {{ environment }}-{{ customer }}[--{{ feature_title }}]

The application name is generated using the following pattern:

    {{ environment }}-{{ customer }}-{{ application }}[--{{ feature_title }}]

where:

* `environment`: the name of the environment (development, feature, staging,
  preprod or production)
* `customer`: the one-word name of the customer site (_e.g._ `ucsd`, `hvrd`,
  `uca`). We enforce this name to at most 6 characters, because it is used in a
  strict database user & name pattern that must also include the environment and
  targeted application name within 16 characters (yes MySQL we are looking at
  you ðŸ˜‰).
* `application`: the one-word name of the application (lms, cms, etc.)
* `feature_title`: the slugified title of the feature. Only applicable when the
  `environment` is equal to `feature`.

The application name is used as a subdomain of the `domain_name` defined in
`group_vars/all/openshift_routes.yml` (_e.g._ `example.com`) to compose urls,
except for:

* the development environment where urls are set as a subdomain of nip.io,
  the subdomain being the local IP address of the MiniShift instance
  (**e.g.** 192.168.0.1.nip.io),
* the production environment where urls are set to the customer's domain.

Here are some examples of valid urls on the `example.com` platform:

* staging-campus-cms.example.com
* staging-campus-lms.example.com
* preprod-fun-lms.example.com
* feature-coporate-lms--change-background-color-on-contact-form.example.com

All these development urls are protected by basic authentication. For this
purpose, an `htpasswd` file is generated in the `nginx` container upon startup:

* the login is set to the one-word customer name,
* the password is an auto-generated secret (see below),
* the login and password are used to generate the `htpasswd` file upon startup
  of the `nginx` container,
* the login and password are sent to the customer by email and posted in a
  dedicated `#deploy` Slack channel.

## Configuration

We use OpenShift's `Configmap`s and `Secret`s for our applications' settings and
services configurations.

Credentials are stored as flat yaml encrypted files so that they can simply be
committed in `Arnold`'s repository.

The credential files are encrypted with `ansible-vault` and the vault password
specific to each project is recorded as an `OpenShift` secret while creating the
project:

```yaml
secretKeyRef:
  name: vaultpass
  key: vaultpass
```

When deploying an application that requires credentials:

* the encrypted file is decrypted by the Ansible vault,
* an OpenShift's `Secret` is then generated from those variables definitions,
* this secret is mounted by an `initContainer` in a configuration volume shared
  with the application container or directly injected in the application
  container as environment variables.

We must distinguish two types of credentials:

### 1. Auto-generated secrets

> _This feature is not yet implemented_

These secrets are login/passwords or tokens that are auto-generated by `Arnold`
(see details below).

> The `DJANGO_SECRET_KEY` or `MYSQL_PASSWORD` settings are examples of
> auto-generated secrets.

### 2. Third-party credentials

These credentials are login/passwords or tokens given by third party SaaS
applications. They are known by the development team who subscribed to the
service and added them to the credentials file.

> The `GOOGLE_ANALYTICS_ID` or `SENTRY_DSN` settings are examples of third-party
> credentials.

## Adding a customer site

A customer site is defined by a set of files in three places:

* `group_vars/customer/`: a yaml file bearing the name of the customer, in which
  are defined all the variables that are injected in the Jinja templates to
  generate OpenShift's `Configmaps` and description files adapted for the
  customer,
* `group_vars/secret`: a folder bearing the name of the customer and containing
  a `credentials.vault.yml` vaulted file for each environment,
* `files/configmap/`: an optional folder bearing the name of the customer and
  containing one (or more) `ConfigMap` for each environment, with files specific
  to the customer. These `ConfigMap`s are assembled with the `Configmap`s
  generated from the default templates (see `templates/configmap`) and might
  override them if they redefine the same file for the same application.

The following tasks are necessary to add a new customer in `Arnold`:

* create new projects in `OpenShift` for each environment,
* add a yaml file in `group_vars/customer/` with all customer-specific variables
  or overrides,
* add a directory in `group_vars/secret/` with the directory structure for each
  environment:
  * generate secrets,
  * set third-party credentials in a `credentials.vault.yml` file.
* optionally add a directory in `files/configmap/` to add or override default
  `ConfigMap`s,
* create new databases in the target infrastructure using the auto-generated
  secrets,
* generate vault passwords for each infrastructure:
  * use the vault passwords to encrypt all credential files in the repository,
  * record each vault password as a secret in the corresponding project in
    `OpenShift`,
  * display vault passwords for all environments once in the console so the
    developer can save them in a password manager.

These tasks will be automated in a near future in a `add_customer` playbook.
After running this playbook, the developer will be invited to manually:

* customize variables and files as necessary,
* commit everything to the repository.

## Supported object kinds

Arnold applications can declare various kinds of objects that will be deployed on the
openshift cluster.

### DeploymentConfig

[DeploymentConfig](https://docs.openshift.com/container-platform/3.11/dev_guide/deployments/how_deployments_work.html)
objects are declared in jinja2 template files matching the pattern `dc*.yml.j2` .

> Deployment configurations describe the desired state of a particular component of
 the application as a pod template.

For the purpose of our blue/green deployment process, the name of a
`DeploymentConfig` is dynamic: it is suffixed with a stamp that is unique to the version of the deployed application.

### Service (aka `Blue/Green service`)

[Service](https://kubernetes.io/docs/concepts/services-networking/service/)
objects are declared in jinja2 template files matching the pattern `svc*.yml.j2`

They are part of our blue/green deployment process and their name are also dynamic: they are suffixed with a deployment stamp.
Each deployed version of an application has its own set of services and is referred to as a `stack`.

Services allow components (i.e. `pods`) of a deployed application to communicate with each other while also
ensuring that the application stack is consistent.

### Static Service

*Static Service* objects are declared in jinja2 template files matching the pattern `static-svc*.yml.j2`.

Technically, they are pure kubernetes [Service](https://kubernetes.io/docs/concepts/services-networking/service/) objects.
But in arnold, we use them for a specific case in our blue/green compatible applications.

B/G Services are helpful for blue/green deployments and for internal communication inside the same application, but their dynamic name makes it difficult to be used by other applications.
That's why we introduced static services.

Static services, as their name suggests, are services with a name that does not change.

Static services are declined in 3 variants (i.e. the static service `foo` is declined in `foo-previous`, `foo-current` and `foo-next`).
Each variant targets the corresponding stack.

The 2 use cases for a static service are:

- Exposing an application to another application
- Exposing an application to a route

### Route

[Route](https://docs.openshift.com/container-platform/3.11/architecture/networking/routes.html)
objects are declared in jinja2 template files matching the pattern `route*.yml.j2`.

> An OpenShift Container Platform route exposes a service at a host name, such as www.example.com, so that external clients can reach it by name.

If you want to expose your application to external clients via HTTP, you must declare a route.

Routes work with static services in a blue/green compatible application. So you must declare a static service if you declare a route.

Each route is declined in 3 variants:
i.e. if you declare a route `bar`, it is declined in `bar-previous`, `bar-current` and `bar-next`.

And each variant targets the corresponding variant of the static service.

### ConfigMap

ConfigMaps are automagically generated if you create files in the `configs` directory of a service template.

For example, if I create the file `apps/my-app/templates/services/my-service/config/test.yml.j2`, a ConfigMap will be generated with a key named `test.yml` and with the content of the rendered template as a `value`.

This might change in the future.

### Jobs

[Job](https://docs.openshift.com/container-platform/3.11/dev_guide/jobs.html)
objects are declared in jinja2 template files matching the pattern `job_*.yml.j2`.

They are launched when you deploy your application.

They can be launched before (default) or after the deployment of your DeploymentConfigs.

To run a job after the deployment, you must set a label `job_type: "post"`

### Endpoint

For specific cases (i.e. having a kubernetes service that targets a machine outside of the kubernetes cluster), we may want to declare a [Service](https://kubernetes.io/docs/concepts/services-networking/service/) without `selector`.

In this case, we can manage the endpoints of the service by declaring them in jinja2 template files matching the pattern `ep*.yml.j2`
